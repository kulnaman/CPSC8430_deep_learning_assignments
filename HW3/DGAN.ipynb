{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import string\n",
    "from random import randint\n",
    "from collections import defaultdict, Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import utils\n",
    "from itertools import chain\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from inception_score import get_inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1=nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0)\n",
    "        self.batch1=nn.BatchNorm2d(num_features=1024)\n",
    "        self.activ1=nn.ReLU(True)\n",
    "        # State (1024x4x4)\n",
    "        self.conv2=nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch2=nn.BatchNorm2d(num_features=512)\n",
    "        self.activ2=nn.ReLU(True)\n",
    "        # State (512x8x8)\n",
    "        self.conv3=nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch3=nn.BatchNorm2d(num_features=256)\n",
    "        self.activ3=nn.ReLU(True)\n",
    "        # State (256x16x16)\n",
    "        self.conv4=nn.ConvTranspose2d(in_channels=256, out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        self.output=nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.batch1(x)\n",
    "        x=self.activ1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.batch2(x)\n",
    "        x=self.activ2(x)     \n",
    "        x=self.conv3(x)\n",
    "        x=self.batch3(x)\n",
    "        x=self.activ3(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Generator(torch.nn.Module):\n",
    "#     def __init__(self, channels=3):\n",
    "#         super().__init__()\n",
    "#         # Filters [1024, 512, 256]\n",
    "#         # Input_dim = 100\n",
    "#         # Output_dim = C (number of channels)\n",
    "#         self.main_module = nn.Sequential(\n",
    "#             # Z latent vector 100\n",
    "#             nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n",
    "#             nn.BatchNorm2d(num_features=1024),\n",
    "#             nn.ReLU(True),\n",
    "\n",
    "#             # State (1024x4x4)\n",
    "#             nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(num_features=512),\n",
    "#             nn.ReLU(True),\n",
    "\n",
    "#             # State (512x8x8)\n",
    "#             nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(num_features=256),\n",
    "#             nn.ReLU(True),\n",
    "\n",
    "#             # State (256x16x16)\n",
    "#             nn.ConvTranspose2d(in_channels=256, out_channels=channels, kernel_size=4, stride=2, padding=1))\n",
    "#             # output of main module --> Image (Cx32x32)\n",
    "\n",
    "#         self.output = nn.Tanh()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.main_module(x)\n",
    "#         return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3, out_channels=256, kernel_size=4, stride=2, padding=1)\n",
    "        self.activ1=nn.LeakyReLU(0.2, inplace=True)\n",
    "        # State (1024x4x4)\n",
    "        self.conv2=nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch2=nn.BatchNorm2d(512)\n",
    "        self.activ2=nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv3=nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch3=nn.BatchNorm2d(1024)\n",
    "        self.activ3=nn.LeakyReLU(0.2, inplace=True)\n",
    "        # State (1024x4x4)\n",
    "\n",
    "        self.conv4=nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0)\n",
    "        self.output=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.activ1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.batch2(x)\n",
    "        x=self.activ2(x)     \n",
    "        x=self.conv3(x)\n",
    "        x=self.batch3(x)\n",
    "        x=self.activ3(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(torch.nn.Module):\n",
    "#     def __init__(self, channels=3):\n",
    "#         super().__init__()\n",
    "#         # Filters [256, 512, 1024]\n",
    "#         # Input_dim = channels (Cx64x64)\n",
    "#         # Output_dim = 1\n",
    "#         self.main_module = nn.Sequential(\n",
    "#             # Image (Cx32x32)\n",
    "#             nn.Conv2d(in_channels=channels, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # State (256x16x16)\n",
    "#             nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "#             # State (512x8x8)\n",
    "#             nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(1024),\n",
    "#             nn.LeakyReLU(0.2, inplace=True))\n",
    "#             # outptut of main module --> State (1024x4x4)\n",
    "\n",
    "#         self.output = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0),\n",
    "#             # Output 1\n",
    "#             nn.Sigmoid())\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.main_module(x)\n",
    "#         return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv1): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (batch1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ1): ReLU(inplace=True)\n",
       "  (conv2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (batch2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ2): ReLU(inplace=True)\n",
       "  (conv3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (batch3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ3): ReLU(inplace=True)\n",
       "  (conv4): ConvTranspose2d(256, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (output): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model=Discriminator()\n",
    "gen_model=Generator()\n",
    "disc_model.to(device)\n",
    "gen_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv1): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (batch1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ1): ReLU(inplace=True)\n",
       "  (conv2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (batch2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ2): ReLU(inplace=True)\n",
       "  (conv3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (batch3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ3): ReLU(inplace=True)\n",
       "  (conv4): ConvTranspose2d(256, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (output): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1): Conv2d(3, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (activ1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv2): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (batch2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv3): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (batch3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activ3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv4): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(batchsize):\n",
    "    trans = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./files/', train=True, download=True, transform=trans)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='./files/', train=False, download=True, transform=trans)\n",
    "\n",
    "    \n",
    "    train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = data_utils.DataLoader(test_dataset,  batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=0.0002\n",
    "epochs=50\n",
    "batch_size=32\n",
    "beta_1,beta_2=0.5,0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.BCELoss()\n",
    "gen_optim=torch.optim.Adam(gen_model.parameters(), lr=learn_rate,betas=(beta_1,beta_2))\n",
    "disc_optim=torch.optim.Adam(disc_model.parameters(), lr=learn_rate,betas=(beta_1,beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(gen,disc):\n",
    "    torch.save(gen.state_dict(), './generator_dcgan.pkl')\n",
    "    torch.save(disc.state_dict(), './discriminator_dcgan.pkl')\n",
    "    print('Models save to ./generator.pkl & ./discriminator.pkl ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(train_loader,loss):\n",
    "#     for images,_ in train_loader:\n",
    "        \n",
    "#         images=images.to(device)\n",
    "#         disc_model.to(device)\n",
    "#         gen_model.to(device)\n",
    "#         noise = torch.rand((images.shape[0], 100, 1, 1)).to(device)\n",
    "#         real_labels = torch.ones(images.shape[0]).to(device)\n",
    "#         fake_labels = torch.zeros(images.shape[0]).to(device)\n",
    "#         # Train discriminator\n",
    "\n",
    "#         # Compute BCE_Loss using real images\n",
    "#         real_image_disc_output = disc_model(images)\n",
    "#         d_loss_real = loss(real_image_disc_output.flatten(), real_labels)\n",
    "#         real_score = real_image_disc_output\n",
    "\n",
    "#         # Compute BCE Loss using fake images\n",
    "\n",
    "#         fake_images_generator_output = gen_model(noise)\n",
    "#         output_using_fake_image = disc_model(fake_images_generator_output)\n",
    "#         d_loss_fake =loss(output_using_fake_image.flatten(), fake_labels)\n",
    "#         fake_score = output_using_fake_image\n",
    "\n",
    "#         # Optimize discriminator\n",
    "#         d_loss = d_loss_real + d_loss_fake\n",
    "#         disc_model.zero_grad()\n",
    "#         d_loss.backward()\n",
    "#         disc_optim.step()\n",
    "\n",
    "#         # Train generator\n",
    "#         # Compute loss with fake images\n",
    "#         noise = torch.rand((images.shape[0], 100, 1, 1)).to(device)\n",
    "#         fake_images_generator_output = gen_model(noise)\n",
    "        \n",
    "#         outputs_of_discrimiator = disc_model(fake_images_generator_output)\n",
    "        \n",
    "#         g_loss = loss(outputs_of_discrimiator.flatten(), real_labels)\n",
    "\n",
    "#         # Optimize generator\n",
    "#         disc_model.zero_grad()\n",
    "#         gen_model.zero_grad()\n",
    "#         g_loss.backward()\n",
    "#         gen_optim.step()\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def train(train_loader):\n",
    "        generator_iter = 0\n",
    "        file = open(\"inception_score_graph.txt\", \"w\")\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            for i, (images, _) in enumerate(train_loader):\n",
    "                # Check if round number of batches\n",
    "                if i == train_loader.dataset.__len__() // batch_size:\n",
    "                    break\n",
    "\n",
    "                z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n",
    "                real_labels = torch.ones(batch_size).to(device)\n",
    "                fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "                images=images.to(device)\n",
    "\n",
    "\n",
    "                # Train discriminator\n",
    "                # Compute BCE_Loss using real images\n",
    "                outputs = disc_model(images)\n",
    "                d_loss_real = loss(outputs.flatten(), real_labels)\n",
    "                real_score = outputs\n",
    "\n",
    "                # Compute BCE Loss using fake images\n",
    "                z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n",
    "\n",
    "                fake_images = gen_model(z)\n",
    "                outputs = disc_model(fake_images)\n",
    "                d_loss_fake = loss(outputs.flatten(), fake_labels)\n",
    "                fake_score = outputs\n",
    "\n",
    "                # Optimize discriminator\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                disc_model.zero_grad()\n",
    "                d_loss.backward()\n",
    "                disc_optim.step()\n",
    "\n",
    "                # Train generator\n",
    "                # Compute loss with fake images\n",
    "                z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n",
    "\n",
    "                fake_images = gen_model(z)\n",
    "                outputs = disc_model(fake_images)\n",
    "                g_loss = loss(outputs.flatten(), real_labels)\n",
    "\n",
    "                # Optimize generator\n",
    "                disc_model.zero_grad()\n",
    "                gen_model.zero_grad()\n",
    "                g_loss.backward()\n",
    "                gen_optim.step()\n",
    "                generator_iter += 1\n",
    "\n",
    "\n",
    "                if generator_iter % 1000 == 0:\n",
    "                    # Workaround because graphic card memory can't store more than 800+ examples in memory for generating image\n",
    "                    # Therefore doing loop and generating 800 examples and stacking into list of samples to get 8000 generated images\n",
    "                    # This way Inception score is more correct since there are different generated examples from every class of Inception model\n",
    "                    sample_list = []\n",
    "                    for i in range(10):\n",
    "                        z = Variable(torch.randn(800, 100, 1, 1)).to(device)\n",
    "                        samples = gen_model(z)\n",
    "                        sample_list.append(samples.data.cpu().numpy())\n",
    "                    \n",
    "                    # Flattening list of lists into one list of numpy arrays\n",
    "                    new_sample_list = list(chain.from_iterable(sample_list))\n",
    "                    print(\"Calculating Inception Score over 8k generated images\")\n",
    "                    # Feeding list of numpy arrays\n",
    "                    inception_score = get_inception_score(new_sample_list, cuda=True, batch_size=32,\n",
    "                                                          resize=True, splits=10)\n",
    "                    print('Epoch-{}'.format(epoch + 1))\n",
    "\n",
    "                    if not os.path.exists('training_result_images/'):\n",
    "                        os.makedirs('training_result_images/')\n",
    "\n",
    "                    # Denormalize images and save them in grid 8x8\n",
    "                    z = Variable(torch.randn(800, 100, 1, 1)).to(device)\n",
    "                    samples = gen_model(z)\n",
    "                    samples = samples.mul(0.5).add(0.5)\n",
    "                    samples = samples.data.cpu()[:64]\n",
    "                    grid = utils.make_grid(samples)\n",
    "                    utils.save_image(grid, 'training_result_images/img_generatori_iter_{}.png'.format(str(generator_iter).zfill(3)))\n",
    "\n",
    "                    #print(\"Inception score: {}\".format(inception_score))\n",
    "\n",
    "                    # Write to file inception_score, gen_iters, time\n",
    "                    output = str(generator_iter) + \" \" + str(inception_score[0]) + \"\\n\"\n",
    "                    file.write(output)\n",
    "\n",
    "\n",
    "\n",
    "        file.close()\n",
    "\n",
    "        # Save the trained parameters\n",
    "        save_model(gen_model,disc_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(noise, number_of_images):\n",
    "    samples = gen_model(noise).data.cpu().numpy()[:number_of_images]\n",
    "    generated_images = []\n",
    "    for sample in samples:\n",
    "        generated_images.append(sample.reshape(3, 32, 32))\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(G_model_filename,D_model_filename):\n",
    "    D_model_path = os.path.join(os.getcwd(), D_model_filename)\n",
    "    G_model_path = os.path.join(os.getcwd(), G_model_filename)\n",
    "    disc_model.load_state_dict(torch.load(D_model_path))\n",
    "    gen_model.load_state_dict(torch.load(G_model_path))\n",
    "    print('Generator model loaded from {}.'.format(G_model_path))\n",
    "    print('Discriminator model loaded from {}-'.format(D_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkulshr/.conda/envs/DL/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/nkulshr/DL_HW3/inception_score.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x).data.cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:27<2:00:10, 147.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-2\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [05:07<2:03:48, 154.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [07:34<1:58:33, 151.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-4\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [10:14<1:58:40, 154.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [12:41<1:54:02, 152.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-6\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [15:21<1:53:30, 154.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [17:49<1:49:08, 152.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-8\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [20:29<1:48:19, 154.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-9\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [23:09<1:46:51, 156.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [25:36<1:42:20, 153.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-11\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [28:16<1:41:03, 155.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [30:43<1:36:49, 152.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-13\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [33:22<1:35:35, 155.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [35:49<1:31:34, 152.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-15\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [38:29<1:30:18, 154.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [40:56<1:26:23, 152.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-17\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [43:36<1:25:03, 154.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-18\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [46:16<1:23:18, 156.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [48:43<1:19:15, 153.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-20\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [51:23<1:17:40, 155.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [53:50<1:13:51, 152.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-22\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [56:29<1:12:17, 154.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [58:56<1:08:37, 152.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-24\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [1:01:36<1:07:00, 154.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-25\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [1:04:16<1:05:05, 156.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [1:06:43<1:01:22, 153.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-27\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [1:09:22<59:31, 155.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [1:11:49<56:00, 152.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-29\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [1:14:29<54:13, 154.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:16:56<50:49, 152.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-31\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:19:36<48:58, 154.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:22:03<45:41, 152.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-33\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:24:42<43:47, 154.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-34\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:27:22<41:39, 156.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:29:49<38:21, 153.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-36\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:32:29<36:14, 155.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:34:56<33:06, 152.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-38\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:37:36<30:58, 154.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:40:03<27:56, 152.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-40\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:42:42<25:46, 154.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-41\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:45:22<23:25, 156.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:47:49<20:26, 153.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-43\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:50:29<18:06, 155.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:52:55<15:16, 152.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-45\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:55:35<12:54, 154.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:58:02<10:09, 152.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-47\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [2:00:41<07:43, 154.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [2:03:08<05:04, 152.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-49\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [2:05:48<02:34, 154.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-50\n",
      "Calculating Inception Score over 8k generated images\n",
      "Epoch-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [2:08:28<00:00, 154.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models save to ./generator.pkl & ./discriminator.pkl \n",
      "Models save to ./generator.pkl & ./discriminator.pkl \n"
     ]
    }
   ],
   "source": [
    "train_loader,_=create_dataset(batch_size)\n",
    "train(train_loader)\n",
    "save_model(gen_model,disc_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model('./generator_dcgan.pkl','./discriminator_dcgan.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand((64, 100, 1, 1)).to(device)\n",
    "number_of_image=10\n",
    "# generate_img(noise,number_of_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_loader, D_model_path='./discriminator_dcgan.pkl', G_model_path='./generator_dcgan.pkl'):\n",
    "#     load_model( G_model_path,D_model_path)\n",
    "    z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "    samples = gen_model(z)\n",
    "    samples = samples.mul(0.5).add(0.5)\n",
    "    samples = samples.data.cpu()\n",
    "    grid = utils.make_grid(samples)\n",
    "    print(\"Grid of 8x8 images saved to 'dgan_model_image.png'.\")\n",
    "    utils.save_image(grid, 'dgan_model_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Grid of 8x8 images saved to 'dgan_model_image.png'.\n"
     ]
    }
   ],
   "source": [
    "_,test_loader=create_dataset(batch_size)\n",
    "evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
