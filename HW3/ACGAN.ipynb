{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import string\n",
    "from random import randint\n",
    "from collections import defaultdict, Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torchvision import utils\n",
    "from itertools import chain\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from inception_score import get_inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on gen_model and disc_model\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(10, 100)\n",
    "\n",
    "        self.init_size = 32 // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(100, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(3, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = 32 // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 10), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (label_emb): Embedding(10, 100)\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=8192, bias=True)\n",
       "  )\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model=Discriminator()\n",
    "gen_model=Generator()\n",
    "disc_model.to(device)\n",
    "gen_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (label_emb): Embedding(10, 100)\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=8192, bias=True)\n",
       "  )\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (aux_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(batchsize):\n",
    "    trans = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./files/', train=True, download=True, transform=trans)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='./files/', train=False, download=True, transform=trans)\n",
    "\n",
    "    \n",
    "    train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = data_utils.DataLoader(test_dataset,  batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=0.0002\n",
    "epochs=100\n",
    "batch_size=64\n",
    "beta_1,beta_2=0.5,0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optim=torch.optim.Adam(gen_model.parameters(), lr=learn_rate,betas=(beta_1,beta_2))\n",
    "disc_optim=torch.optim.Adam(disc_model.parameters(), lr=learn_rate,betas=(beta_1,beta_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_criterion = nn.BCELoss()\n",
    "class_criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batch_size, 3, 32, 32).to(device)\n",
    "noise = torch.FloatTensor(batch_size, 100, 1, 1).to(device)\n",
    "fixed_noise = torch.FloatTensor(batch_size, 100, 1, 1).normal_(0, 1).to(device)\n",
    "source_label = torch.FloatTensor(batch_size).to(device)\n",
    "class_label = torch.LongTensor(batch_size).to(device)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(input)\n",
    "source_label = Variable(source_label)\n",
    "class_label = Variable(class_label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "fixed_noise_ = np.random.normal(0, 1, (batch_size, 100))\n",
    "random_label = np.random.randint(0, 10, batch_size)\n",
    "random_onehot = np.zeros((batch_size, 10))\n",
    "random_onehot[np.arange(batch_size), random_label] = 1\n",
    "fixed_noise_[np.arange(batch_size), :10] = random_onehot[np.arange(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(gen,disc):\n",
    "    torch.save(gen.state_dict(), './generator_agan.pkl')\n",
    "    torch.save(disc.state_dict(), './discriminator_agan.pkl')\n",
    "    print('Models save to ./generator_agan.pkl & ./discriminator_agan.pkl ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(predict, labels):\n",
    "    correct = 0\n",
    "    pred = predict.data.max(1)[1]\n",
    "    correct = pred.eq(labels.data).cpu().sum()\n",
    "    return correct, len(labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatTensor = torch.cuda.FloatTensor \n",
    "LongTensor = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    file = open(\"inception_score_graph_acgan.txt\", \"w\")\n",
    "    generator_iter = 0\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            batch_size = imgs.shape[0]\n",
    "\n",
    "            # Adversarial ground truths\n",
    "            valid = torch.ones(batch_size).to(device)\n",
    "            fake = torch.zeros(batch_size).to(device)\n",
    "\n",
    "            # Configure input\n",
    "            real_imgs = Variable(imgs.type(FloatTensor)).to(device)\n",
    "            labels = Variable(labels.type(LongTensor)).to(device)\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            gen_optim.zero_grad()\n",
    "\n",
    "            # Sample noise and labels as generator input\n",
    "            z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "            gen_labels = Variable(LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "\n",
    "            # Generate a batch of images\n",
    "            gen_imgs = gen_model(z, gen_labels)\n",
    "\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            validity, pred_label = disc_model(gen_imgs)\n",
    "            g_loss = 0.5 * (source_criterion(validity, valid.unsqueeze(1)) + class_criterion(pred_label, gen_labels))\n",
    "\n",
    "            g_loss.backward()\n",
    "            gen_optim.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            disc_optim.zero_grad()\n",
    "\n",
    "            # Loss for real images\n",
    "            real_pred, real_aux = disc_model(real_imgs)\n",
    "            d_real_loss = (source_criterion(real_pred, valid.unsqueeze(1)) + class_criterion(real_aux, labels)) / 2\n",
    "\n",
    "            # Loss for fake images\n",
    "            fake_pred, fake_aux = disc_model(gen_imgs.detach())\n",
    "            d_fake_loss = (source_criterion(fake_pred, fake.unsqueeze(1)) + class_criterion(fake_aux, gen_labels)) / 2\n",
    "\n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            disc_optim.step()\n",
    "            generator_iter+=1\n",
    "            if generator_iter % 1000 == 0:\n",
    "                # Workaround because graphic card memory can't store more than 800+ examples in memory for generating image\n",
    "                # Therefore doing loop and generating 800 examples and stacking into list of samples to get 8000 generated images\n",
    "                # This way Inception score is more correct since there are different generated examples from every class of Inception model\n",
    "                sample_list = []\n",
    "                for i in range(10):\n",
    "                    z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "                    gen_labels = Variable(LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "                    samples = gen_model(z, gen_labels)\n",
    "                    sample_list.append(samples.data.cpu().numpy())\n",
    "\n",
    "                # Flattening list of lists into one list of numpy arrays\n",
    "                new_sample_list = list(chain.from_iterable(sample_list))\n",
    "    #             print(\"Calculating Inception Score over 8k generated images\")\n",
    "                # Feeding list of numpy arrays\n",
    "                inception_score = get_inception_score(new_sample_list, cuda=True, batch_size=32,\n",
    "                                                      resize=True, splits=10)\n",
    "    #             print('Epoch-{}'.format(epoch + 1))\n",
    "\n",
    "                if not os.path.exists('training_result_images_acgan_real/'):\n",
    "                    os.makedirs('training_result_images_acgan_real/')\n",
    "                if not os.path.exists('training_result_images_acgan_fake/'):\n",
    "                    os.makedirs('training_result_images_acgan_fake/')\n",
    "                # Denormalize images and save them in grid 8x8\n",
    "                z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "                gen_labels = Variable(LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "                samples = gen_model(z, gen_labels)\n",
    "                samples = samples.mul(0.5).add(0.5)\n",
    "                samples = samples.data.cpu()[:64]\n",
    "    #             grid = utils.make_grid(samples)\n",
    "                utils.save_image(samples, 'training_result_images_acgan_fake/img_generatori_iter_{}.png'.format(str(generator_iter).zfill(3)))\n",
    "                utils.save_image(imgs,'training_result_images_acgan_real/img_generatori_iter_real_{}.png'.format(str(generator_iter).zfill(3)))\n",
    "                #print(\"Inception score: {}\".format(inception_score))\n",
    "\n",
    "                # Write to file inception_score, gen_iters, time\n",
    "                output = str(generator_iter) + \" \" + str(inception_score[0]) + \"\\n\"\n",
    "                file.write(output)\n",
    "\n",
    "\n",
    "\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "    # do checkpointing\n",
    "    save_model(gen_model,disc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(noise, number_of_images):\n",
    "    samples = gen(z).data.cpu().numpy()[:number_of_images]\n",
    "    generated_images = []\n",
    "    for sample in samples:\n",
    "        generated_images.append(sample.reshape(3, 32, 32))\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(D_model_filename, G_model_filename):\n",
    "    D_model_path = os.path.join(os.getcwd(), D_model_filename)\n",
    "    G_model_path = os.path.join(os.getcwd(), G_model_filename)\n",
    "    disc_model.load_state_dict(torch.load(D_model_path))\n",
    "    gen_model.load_state_dict(torch.load(G_model_path))\n",
    "    print('Generator model loaded from {}.'.format(G_model_path))\n",
    "    print('Discriminator model loaded from {}-'.format(D_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/nkulshr/.conda/envs/DL/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "  1%|          | 1/100 [00:14<23:49, 14.44s/it]/home/nkulshr/.conda/envs/DL/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/nkulshr/DL_HW3/inception_score.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x).data.cpu().numpy()\n",
      "100%|██████████| 100/100 [25:58<00:00, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models save to ./generator_agan.pkl & ./discriminator_agan.pkl \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader,_=create_dataset(batch_size)\n",
    "train(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_loader, D_model_path='./discriminator_dcgan.pkl', G_model_path='./generator_dcgan.pkl'):\n",
    "#     load_model( G_model_path,D_model_path)\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "    gen_labels = Variable(LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "    samples = gen_model(z, gen_labels)\n",
    "\n",
    "    samples = samples.mul(0.5).add(0.5)\n",
    "    samples = samples.data.cpu()\n",
    "    grid = utils.make_grid(samples)\n",
    "    print(\"Grid of 8x8 images saved to 'acgan_model_image.png'.\")\n",
    "    utils.save_image(grid, 'acgan_model_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Grid of 8x8 images saved to 'acgan_model_image.png'.\n"
     ]
    }
   ],
   "source": [
    "_,test_loader=create_dataset(batch_size)\n",
    "evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
